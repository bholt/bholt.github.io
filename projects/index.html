<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Brandon Holt — Projects</title>

        <meta name="twitter:card" content="summary">
        <meta name="twitter:site" content="@holtbg">
        <meta name="twitter:creator" content="@holtbg">
        <meta name="twitter:title" content="Projects">
        <meta name="twitter:description" content="List of current and recent research and side projects.">

        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <link href="/css/bootstrap.min.css" rel="stylesheet">
        <link href="/css/bootstrap-theme.min.css" rel="stylesheet">
        <link href='https://fonts.googleapis.com/css?family=Lato:300,300italic,700italic,700|Anonymous+Pro' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">

        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <link href="/css/madoko.css" rel="stylesheet">
        <link href="/css/theme.css" rel="stylesheet">
        <link href="/css/syntax.css" rel="stylesheet">
        <!-- <link href='http://fonts.googleapis.com/css?family=News+Cycle|Inconsolata' rel='stylesheet' type='text/css'> -->

        

    </head>
    <body>
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-48525616-1', 'washington.edu');
        ga('send', 'pageview');
      </script>

        <div class="container">
          <div class="header">
            <ul class="nav nav-pills pull-right">
              
              
                
                <li class="nav-item">
                  
                  <a class="nav-link " href="/">
                    Home
                  </a>
                </li>
              
                
                <li class="nav-item">
                  
                  <a class="nav-link active" href="/projects/">
                    Projects
                  </a>
                </li>
              
                
                <li class="nav-item">
                  
                  <a class="nav-link " href="/cv.html">
                    CV
                  </a>
                </li>
              
                
                <li class="nav-item">
                  
                  <a class="nav-link " href="/posts/">
                    Posts
                  </a>
                </li>
              
                
                <li class="nav-item">
                  
                  <a class="nav-link " href="http://github.com/bholt">
                    <i class="fa fa-github"></i>
                  </a>
                </li>
              
                
                <li class="nav-item">
                  
                  <a class="nav-link " href="http://twitter.com/holtbg">
                    <i class="fa fa-twitter"></i>
                  </a>
                </li>
              
            </ul>
            <h2><a class="black" href="/">Brandon Holt</a></h2>
          </div>

          <style>
.container p img { float: right; margin: 1em; max-width: 130px; }
</style>

<p><a name="IPA"></a></p>

<h2 id="disciplined-inconsistency"><a href="http://sampa.cs.washington.edu/projects/disciplined-inconsistency.html">Disciplined Inconsistency</a></h2>

<p><img src="/img/ipa.jpg" alt="IPA"></p>

<p><em>Making consistency safe again.</em></p>

<p>Distributed applications and web services, such as online stores or
social networks, are expected to be scalable, available, responsive,
and fault-tolerant. To meet these steep requirements in the face of
high round-trip latencies, network partitions, server failures, and
load spikes, applications use eventually consistent datastores that
allow them to weaken the consistency of some data.  However, making
this transition is highly error-prone because relaxed consistency
models are notoriously difficult to understand and test.</p>

<p>In this work, we propose a new programming model for distributed data
that makes consistency properties explicit and uses a type system to
enforce <em>consistency safety</em>. With the <em>Inconsistent,
Performance-bound, Approximate</em> (IPA) storage system, programmers
specify performance targets and correctness requirements as
constraints on persistent data structures and handle uncertainty about
the result of datastore reads using new <em>consistency types</em>.  We
implement a prototype of this model in Scala on top of an existing
datastore, Cassandra, and use it to make performance/correctness
tradeoffs in two applications: a ticket sales service and a Twitter
clone. Our evaluation shows that IPA prevents consistency-based
programming errors and adapts consistency automatically in response to
changing network conditions, performing comparably to weak consistency
and 2-10x faster than strong consistency.</p>

<ul>
<li><div class="pub"><strong><a href="http://bholt.github.io/gen/ipa-tr.pdf" class="pub-title">Disciplined Inconsistency</a></strong><br/>Brandon Holt, James Bornholt, Irene Zhang, Dan Ports, Mark Oskin, Luis Ceze<br/><span class="venue"><a href="https://norfolk.cs.washington.edu/htbin-post/unrestricted/tr/list.cgi?sortby=date">Technical Report UW-CSE-16-06-01</a></span> — June 2016<br/><span class="pub"><a href="http://bholt.github.io/gen/ipa-tr.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Paper</a> | <a href="http://bholt.github.io/gen/ipa-tr.html"><i class="fa fa-html5" aria-hidden="true"></i> Html</a> | <a href="https://github.com/bholt/ipa"><i class="fa fa-code-fork" aria-hidden="true"></i> Code</a></span></div></li>
<li><a href="http://127.0.0.1:4000/posts/disciplined-inconsistency.html">Blog post</a></li>
<li><a href="https://github.com/bholt/ipa">Source code <i class="fa fa-github"></i></a></li>
</ul>

<p><a href="http://sampa.cs.washington.edu/projects/disciplined-inconsistency.html">Read more...</a></p>

<p><a name="Claret"></a></p>

<h2 id="claret"><a href="http://sampa.cs.washington.edu/projects/claret.html">Claret</a></h2>

<p><img src="/img/claret.jpg" alt="Claret"></p>

<p><em>Using abstract data types to expose application-level semantics in datastores.</em></p>

<p>Claret brings the clean abstractions of data structures and ADTs to the world of distributed key-value datastores. There is a new data storage model on the rise that bridges the gap between the restrictions of fully relational schemas and SQL, and the completely flat key-value stores. Data structure stores such as <a href="http://redis.io">Redis</a>, <a href="http://basho.com/products/riak-kv/">Riak</a>, and <a href="http://hyperdex.org/">Hyperdex</a> allow programmers to build their persistent data out of whatever data structures make sense: lists, sets, maps, or more specialized data types. Programmers like it because it is simple to use and flexible, but allows them to leverage the power and reusability of the provided complex data structures.</p>

<p>Claret builds on this data structure storage, exposing the abstract semantics of these data types to the underlying distributed datastore to enable new optimizations. Crucially, by exposing the concurrency between commutative ADT operations that already exists in these applications, Claret can provide much stronger guarantees — serializable distributed transactions — with much less cost to throughput and latency than traditional systems. Our model allows programmers to either choose from a library of existing data types or extend the system with custom data types that specifically meet their application&#39;s needs, in order to expose the maximum amount of information to the system. Our prototype datastore implements optimizations that leverage this information, including abstract locks and transaction boosting, operation combining, and operation reordering or phasing.</p>

<ul>
<li><div class="pub"><strong><a href="http://dl.acm.org/authorize?N96590" class="pub-title">Claret: Using Data Types for Highly Concurrent Distributed Transactions</a></strong><br/>Brandon Holt, Irene Zhang, Dan Ports, Mark Oskin, Luis Ceze<br/><span class="venue"><a href="http://papoc.di.uminho.pt">Workshop on Principles and Practice of Consistency (PaPoC&#39;15)</a></span> — April 2015<br/><span class="pub"><a href="http://dl.acm.org/authorize?N96590"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Paper</a> | <a href="/pubs/claret-papoc-slides.pdf"><i class="fa fa-television" aria-hidden="true"></i> Slides</a> | <a href="/files/claret-papoc.key"><i class="fa fa-television" aria-hidden="true"></i> Key</a></span></div></li>
<li>Full paper in submission.</li>
</ul>

<p><a href="http://sampa.cs.washington.edu/projects/claret.html">Read more...</a></p>

<p><a name="Grappa"></a></p>

<h2 id="grappa"><a href="http://grappa.io">Grappa</a></h2>

<p><img src="/img/grappa_logo.svg" class="pull-right" style="width:250px;margin:15px"/>
Scaling irregular applications on commodity hardware.</p>

<p>Irregular applications are those that do lots of hard-to-predict, data-dependent, fine-grained memory accesses. Examples include graph analytics, molecular dynamics, circuit simulation, neuromorphic computation, and many more. The lack of spatial and temporal locality in these applications makes it difficult to scale them beyond a single node because commodity networks need large packets to get near their peak throughput. The goal of this project is to make it easier to develop and run those kinds of applications on large compute clusters. We see the same few tricks being implemented over and over when irregular applications are tuned for maximum performance, such as rewriting parts to buffer communication, using asynchronous callbacks to overlap communication and disk I/O with computation. In addition to being wasteful, this process can be error-prone.</p>

<p>The core is a runtime system we are developing that automatically aggregates small messages to improve network bandwidth, using massive multithreading to tolerate the increased latency. All we ask is that the programmer expose <em>sufficient parallelism</em>, a quantity that is not lacking in these &quot;Big Data&quot; applications. Our highly-optimized runtime can then manage moving data and computation around the cluster, performing tricks such as issuing hardware pre-fetches and carefully managing the L1 cache, performing extremely lightweight context switches, and coordinating RDMA transfers to get maximum throughput on the network.</p>

<p>A full list of publications for this project and more information can be found on our project website: <a href="http://grappa.io">grappa.io</a>, the most up-to-date paper is <em><a href="http://sampa.cs.washington.edu/grappa/papers/grappa-tr-14-05-03.pdf">Latency Tolerant Distributed Shared Memory</a></em>.</p>

<p>Grappa is also now <strong>open source</strong>! We would love to help people try it out on their own problems. Check it out on <a href="http://github.com/uwsampa/grappa">Github</a>.</p>

<p>A couple sub-projects related to Grappa that I&#39;ve worked on are listed below.</p>

<h3 id="alembic">Alembic</h3>

<p>One of the primary tricks to Grappa&#39;s success is moving computation to where data, which works especially well in low-locality situations. However, explicitly writing these <em>delegate operations</em> breaks the PGAS shared memory abstraction, tying code to one particular memory layout, and making writing performant distributed applications tedious. <em>Alembic</em> is a compiler analysis written for <a href="http://llvm.org">LLVM</a> that automatically transforms threads to do computation migration to improve locality. Using a technique similar to continuation-passing style transformation, Alembic chooses the best places to migrate, reorders memory instructions, and splits threads into a series of messages, providing high-performance migrating threads automatically. This work will be presented at OOPSLA in October:</p>

<ul>
<li><div class="pub"><strong><a href="http://sampa.cs.washington.edu/papers/oopsla14-alembic.pdf" class="pub-title">Alembic: Automatic Locality Extraction via Migration</a></strong><br/>Brandon Holt, Preston Briggs, Luis Ceze, Mark Oskin<br/><span class="venue"><a href="http://2014.splashcon.org/track/oopsla2014">OOPSLA&#39;14</a></span> — October 2014<br/><span class="pub"><a href="http://sampa.cs.washington.edu/papers/oopsla14-alembic.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Paper</a> | <a href="/pubs/alembic-oopsla.pdf"><i class="fa fa-television" aria-hidden="true"></i> Slides</a> | <a href="/pubs/alembic-oopsla.key"><i class="fa fa-television" aria-hidden="true"></i> Key</a> | <a href="https://github.com/uwsampa/grappa/tree/compiler/compiler"><i class="fa fa-code-fork" aria-hidden="true"></i> Code</a></span></div></li>
<li>A post summarizing this work: <a href="/posts/alembic-appearing-at-oopsla14.html">Alembic: Distilling C++ into high performance Grappa</a></li>
</ul>

<h3 id="flat-combining">Flat combining</h3>

<p>The general idea is that synchronization on global shared data structures can be massively improved by waiting and combining many operations together, and Grappa&#39;s massive multithreading allows us to tolerate this additional latency.</p>

<ul>
<li><div class="pub"><strong><a href="/pubs/holt-pgas13.pdf" class="pub-title">Flat Combining Synchronized Global Data Structures</a></strong><br/>Brandon Holt, Jacob Nelson, Brandon Myers, Preston Briggs, Luis Ceze, Simon Kahan, Mark Oskin<br/><span class="venue"><a href="http://www.pgas2013.org.uk">International Conference on PGAS Programming Models (PGAS&#39;14)</a></span> — October 2013<br/><span class="pub"><a href="/pubs/holt-pgas13.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Paper</a> | <a href="/pubs/holt-pgas13-slides.pdf"><i class="fa fa-television" aria-hidden="true"></i> Slides</a> | <a href="https://github.com/uwsampa/grappa"><i class="fa fa-code-fork" aria-hidden="true"></i> Code</a></span></div></li>
<li><div class="pub"><strong>Turning Contention Into Cooperation</strong><br/><span class="venue">UW CSE Qualifying Examination Talk</span> — December 2013<br/><span class="pub"><a href="/pubs/holt-quals.pdf"><i class="fa fa-television" aria-hidden="true"></i> Slides</a></span></div></li>
</ul>

<h3 id="task-migration-simulation">Task migration simulation</h3>

<p><a href="http://www.cs.washington.edu/homes/bdmyers/">Brandon Myers</a> and I submitted a workshop paper to <a href="https://www.usenix.org/conference/hotpar12">HotPar &#39;12</a> exploring whether it is possible to make profitable predictions about when to move a task its the data (migration) rather than moving the data. Our study involved instrumenting the shared memory accesses in a few simple benchmarks, collecting an execution trace, and simulating the cost of data movement under different migration policies, including an optimal migration schedule.</p>

<ul>
<li><div class="pub"><strong><a href="https://www.usenix.org/system/files/conference/hotpar12/hotpar12-final46.pdf" class="pub-title">Do we need a crystal ball for task migration?</a></strong><br/>Brandon Myers, Brandon Holt<br/><span class="venue"><a href="https://www.usenix.org/conference/hotpar12">USENIX Workshop on Hot Topics in Parallelism (HotPar&#39;12)</a></span> — July 2012<br/><span class="pub"><a href="https://www.usenix.org/system/files/conference/hotpar12/hotpar12-final46.pdf"><i class="fa fa-file-pdf-o" aria-hidden="true"></i> Paper</a></span></div></li>
</ul>

<hr>

<p><a name="Igor"></a></p>

<h2 id="tools">Tools</h2>

<h3 id="igor"><a href="http://github.com/bholt/igor">Igor</a></h3>

<p><img src="/img/mini-igor.jpg" class="img-thumbnail pull-right" style="width:250px;margin:15px"/></p>

<p>This project was born out of necessity when we wanted to be able to collect output from many experiments in Grappa and related projects. We also needed a way to easily enumerate a large multi-variate parameter space, especially when trying to find the right parameters to maximize performance for Grappa. This script aims to help with generating a large number of experiments, parsing their output, and storing experiment inputs and outcomes to a SQLite database automatically. For now, it simply supports having a static script that runs all the experiments in a single batch and gathers the results automatically. We would like to make the experience more interactive, where a prompt can be used to schedule new parameter sweeps, monitor progress of existing experiments, inspect gathered data points, and visualize preliminary results. A complete re-write to support this goal will probably happen--eventually.</p>

<hr>

<h3 id="project-archive"><a href="old.html">Project Archive</a></h3>



          <div class="footer">
            <p>Brandon Holt &#8212; <a href="http://www.cs.washington.edu/">Computer Science &amp; Engineering</a> at the <a href="http://www.washington.edu/">University of Washington</a></p>
          </div>
        </div>

      <!-- load javascript last -->

      <script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
      <script src="//github.hubspot.com/tether/dist/js/tether.js"></script>
      <script src="/js/bootstrap.min.js"></script>

      <!-- support retina -->
      <script type="text/javascript" src="/js/srcset-polyfill.js"></script>

    </body>
</html>
